2Ô∏è‚É£ Python Script #1 ‚Äî PR Metrics (ready to run)
scripts/pr_metrics.py
This script collects:
PR count
Average merge time
Average time to first review
Conflict count (best-effort)
Outputs CSV + console summary



import requests
import os
import csv
from datetime import datetime

GITHUB_TOKEN = os.environ["GITHUB_TOKEN"]
REPO = os.environ["GITHUB_REPOSITORY"]  # org/repo
API = "https://api.github.com"

headers = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github+json"
}

def get_prs():
    prs = []
    page = 1
    while True:
        r = requests.get(
            f"{API}/repos/{REPO}/pulls",
            headers=headers,
            params={"state": "closed", "per_page": 100, "page": page}
        )
        data = r.json()
        if not data:
            break
        prs.extend(data)
        page += 1
    return prs

prs = get_prs()

rows = []
merge_times = []
review_times = []
conflicts = 0

for pr in prs:
    if not pr.get("merged_at"):
        continue

    created = datetime.fromisoformat(pr["created_at"].replace("Z", ""))
    merged = datetime.fromisoformat(pr["merged_at"].replace("Z", ""))
    merge_hours = (merged - created).total_seconds() / 3600
    merge_times.append(merge_hours)

    reviews = requests.get(
        f'{API}/repos/{REPO}/pulls/{pr["number"]}/reviews',
        headers=headers
    ).json()

    if reviews:
        first_review = datetime.fromisoformat(reviews[0]["submitted_at"].replace("Z", ""))
        review_hours = (first_review - created).total_seconds() / 3600
        review_times.append(review_hours)

    if pr.get("mergeable_state") == "dirty":
        conflicts += 1

    rows.append([
        pr["number"],
        pr["title"],
        round(merge_hours, 2),
        pr["user"]["login"]
    ])

os.makedirs("reports", exist_ok=True)

with open("reports/pr_metrics.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["PR Number", "Title", "Merge Time (hrs)", "Author"])
    writer.writerows(rows)

print("PR METRICS SUMMARY")
print("------------------")
print(f"Total merged PRs: {len(rows)}")
print(f"Average merge time (hrs): {round(sum(merge_times)/len(merge_times), 2)}")
if review_times:
    print(f"Average time to first review (hrs): {round(sum(review_times)/len(review_times), 2)}")
print(f"PRs with conflicts: {conflicts}")







3Ô∏è‚É£ Python Script #2 ‚Äî Branch Metrics
scripts/branch_metrics.py

Tracks:
Branch count
Branch age
Stale branches (>30 days)
Outputs CSV + summary


import requests
import os
import csv
from datetime import datetime, timezone

GITHUB_TOKEN = os.environ["GITHUB_TOKEN"]
REPO = os.environ["GITHUB_REPOSITORY"]
API = "https://api.github.com"

headers = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github+json"
}

branches = requests.get(
    f"{API}/repos/{REPO}/branches",
    headers=headers
).json()

now = datetime.now(timezone.utc)
rows = []
stale = 0

for b in branches:
    commit = requests.get(
        b["commit"]["url"],
        headers=headers
    ).json()

    commit_date = datetime.fromisoformat(
        commit["commit"]["committer"]["date"].replace("Z", "+00:00")
    )

    age_days = (now - commit_date).days
    if age_days > 30:
        stale += 1

    rows.append([b["name"], age_days])

os.makedirs("reports", exist_ok=True)

with open("reports/branch_metrics.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["Branch Name", "Age (days since last commit)"])
    writer.writerows(rows)

print("BRANCH METRICS SUMMARY")
print("----------------------")
print(f"Total branches: {len(rows)}")
print(f"Stale branches (>30 days): {stale}")















4Ô∏è‚É£ GitHub Actions Workflow (automation)
.github/workflows/branch-pr-metrics.yml

This:
Runs weekly
Can be run manually
Uploads reports as artifacts (very demo-friendly)



name: Branch and PR Metrics

on:
  workflow_dispatch:
  schedule:
    - cron: '0 2 * * 1' # Every Monday

jobs:
  metrics:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install requests

      - name: Run PR metrics
        run: python scripts/pr_metrics.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Run Branch metrics
        run: python scripts/branch_metrics.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload metrics reports
        uses: actions/upload-artifact@v4
        with:
          name: branch-pr-metrics
          path: reports/











5Ô∏è‚É£ How to demo this to your team (talking points)

You can literally say this üëá

‚ÄúWe‚Äôve automated branch and PR analytics using GitHub APIs.
Every week we collect PR merge time, review delays, conflicts, and stale branches.
This gives us data to validate whether our branching strategy is actually scaling.‚Äù

Then show:

‚úÖ Workflow run

‚úÖ Artifact ‚Üí CSV files

‚úÖ Console summary logs

That directly hits acceptance criteria.

6Ô∏è‚É£ Jira ‚ÄúChange Implemented‚Äù (copy-paste)

Implemented automated branch and PR analytics using GitHub Actions and custom scripts to capture merge time, review latency, conflicts, and stale branches. Reports are generated weekly and can be used to drive data-backed improvements to branching strategy.








